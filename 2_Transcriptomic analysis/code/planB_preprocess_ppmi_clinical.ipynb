{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used to combine all clinical data for PPMI cohort (ignore GWAS data availability). It does not impute missing values, and will normalize values, and include baseline scores. Most code is copied from ppmi_manqi/preprocessed_code/combine_all_into_one.py. The results are used in RNAseq analysis planB step1: y~ beta1 * time+covariate(age, baseline, med, ..) (no GWAS) and step2: gene ~ beta2 * time+covariate\n",
    "\n",
    "Results are: \n",
    "1) planB_clinical.csv. Normalized and unimputed clinical data for all PPMI samples (ignore GWAS data availability) that are PD, >1vist & >0.5yr gap, has RNA data\n",
    "2) planB_meta.csv. Meta data with normalized ledd, pd_duration_time for PD RNAseq samples\n",
    "3) planB_count.csv. Count data for PD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from extraction_function import extract_primary_diag\n",
    "from cal_additional_scores import *\n",
    "import scipy.stats as stats\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### data path\n",
    "ppmi_data_path='../../ppmi_manqi/preprocessed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/2720227731.py:9: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  clinical_df=pd.read_csv(all_clinical_file)\n"
     ]
    }
   ],
   "source": [
    "all_clinical_file=ppmi_data_path+'longitudinal_all_samples_remove_dupDates.csv'\n",
    "all_biospecimen_file=ppmi_data_path+'biospecimen_all_samples.csv'\n",
    "all_static_file=ppmi_data_path+'static_all_samples.csv'\n",
    "patient_visit_file=ppmi_data_path+'patient_event_date.csv'\n",
    "ledd_file=ppmi_data_path+'ledd.csv'\n",
    "\n",
    "patient_visit_df=pd.read_csv(patient_visit_file)\n",
    "ledd_df=pd.read_csv(ledd_file)\n",
    "clinical_df=pd.read_csv(all_clinical_file)\n",
    "biospecimen_df=pd.read_csv(all_biospecimen_file)\n",
    "\n",
    "static_df=pd.read_csv(all_static_file)\n",
    "diag_df=extract_primary_diag(path='../../ppmi_manqi/ppmi_data/')\n",
    "\n",
    "visit_list = ['BL'] + [\"V%02d\" % i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: 3390 samples\n",
      "filter on enroll status: 2381 samples\n",
      "keep PD cohort only: 1034 samples\n",
      "keep PD diagnosis only: 982 samples\n"
     ]
    }
   ],
   "source": [
    "############# filter on static\n",
    "### select static columns\n",
    "static_keep_dict={'PATNO':'PATNO',\n",
    "             'SXDT':'symptom_date','PDDXDT':'diagnosis_date',\n",
    "             'ANYFAMPD':'is_family_pd','COHORT':'COHORT',\n",
    "             'ENROLL_DATE':'ENROLL_DATE','ENROLL_STATUS':'ENROLL_STATUS','ENROLL_AGE':'ENROLL_AGE',\n",
    "             'BIRTHDT':'BIRTHDT','SEX':'SEX','HANDED':'HANDED','EDUCYRS':'EDUCYRS', 'RAWHITE':'is_white'}\n",
    "static_df=static_df[list(static_keep_dict.keys())]\n",
    "static_df.rename(columns=static_keep_dict, inplace=True)\n",
    "print('original data: '+str(static_df.shape[0])+' samples')\n",
    "## remove withdraw patients\n",
    "static_df=static_df[static_df.ENROLL_STATUS.isin(['Enrolled','Complete','Screened','Baseline'])]#2381\n",
    "static_df.drop(columns=['ENROLL_STATUS'],inplace=True)\n",
    "print('filter on enroll status: '+str(static_df.shape[0])+' samples')\n",
    "## use PD samples only\n",
    "static_df=static_df[static_df.COHORT==1]\n",
    "print('keep PD cohort only: '+str(static_df.shape[0])+' samples')\n",
    "## use PD diagnosis only\n",
    "diag1=diag_df.loc[diag_df.PATNO.isin(static_df.PATNO)]\n",
    "id1=list(set(list(diag1.loc[diag1.PRIMDIAG==1]['PATNO'])))#ids whose diagnosis is PD\n",
    "static_df=static_df.loc[static_df.PATNO.isin(id1)]\n",
    "print('keep PD diagnosis only: '+str(static_df.shape[0])+' samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no need to filter sample ids\n",
    "df1 = static_df\n",
    "sample_ids=list(df1.PATNO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Merge longitudinal\n",
    "patient_visit_df=patient_visit_df.loc[patient_visit_df.EVENT_ID.isin(visit_list)]\n",
    "patient_visit_df=patient_visit_df.loc[patient_visit_df.PATNO.isin(sample_ids)]\n",
    "\n",
    "ledd_df=ledd_df.loc[ledd_df.EVENT_ID.isin(visit_list)]\n",
    "ledd_df=ledd_df.loc[ledd_df.PATNO.isin(sample_ids)]\n",
    "\n",
    "biospecimen_df=biospecimen_df.loc[biospecimen_df.EVENT_ID.isin(visit_list)]\n",
    "biospecimen_df=biospecimen_df.loc[biospecimen_df.PATNO.isin(sample_ids)]\n",
    "\n",
    "clinical_df=clinical_df.loc[clinical_df.PATNO.isin(sample_ids)]\n",
    "clinical_df=clinical_df.loc[clinical_df.EVENT_ID.isin(visit_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/4134004619.py:4: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_clinical_df=pd.read_csv(all_clinical_file0)\n",
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/4134004619.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imputed_values.dropna(inplace=True)#remove na\n"
     ]
    }
   ],
   "source": [
    "### Impute moca BL value\n",
    "# Almost all moca are NA at BL, which makes further normalization infeasible. Here, we imput moca BL by moca SC \n",
    "all_clinical_file0=ppmi_data_path+'longitudinal_all_samples.csv'#data contains SC\n",
    "all_clinical_df=pd.read_csv(all_clinical_file0)\n",
    "all_clinical_df=all_clinical_df.loc[all_clinical_df.PATNO.isin(sample_ids)]\n",
    "moca_sc_df=all_clinical_df.loc[all_clinical_df.EVENT_ID=='SC'][['PATNO','EVENT_ID','INFODT','MCATOT']]#moca SC df\n",
    "\n",
    "moca_noSC_df=clinical_df[['PATNO','EVENT_ID','INFODT','MCATOT']]#non SC moca df\n",
    "moca_sub_df=pd.concat([moca_noSC_df,moca_sc_df])# all moca df\n",
    "\n",
    "# impute moca BL by SC\n",
    "for index, row in moca_noSC_df.iterrows():\n",
    "    patno = row['PATNO']\n",
    "    event = row['EVENT_ID']\n",
    "    if event == 'BL':\n",
    "        if pd.isnull(row['MCATOT']):  # is BL is na\n",
    "            ## impute by SC\n",
    "            # bl_date = row['INFODT']\n",
    "            one_sample = moca_sub_df.loc[moca_sub_df.PATNO == patno]\n",
    "            if 'SC' in list(one_sample.EVENT_ID):#if has SC\n",
    "                imputed_values = one_sample.loc[one_sample.EVENT_ID=='SC']['MCATOT']\n",
    "                imputed_values.dropna(inplace=True)#remove na\n",
    "                imputed_values = list(set(imputed_values))#remove duplicate\n",
    "                if len(imputed_values)==1:\n",
    "                    imputed_value=imputed_values[0]\n",
    "                elif len(imputed_values)>1:\n",
    "                    print('multiple value in SC')\n",
    "                    imputed_value = np.nan\n",
    "                else:\n",
    "                    imputed_value = np.nan\n",
    "            else:\n",
    "                imputed_value=np.nan\n",
    "            moca_noSC_df.at[index, 'MCATOT'] = imputed_value\n",
    "        else:\n",
    "            pass  # no need to impute\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "clinical_df['MCATOT_imputeBL']=moca_noSC_df['MCATOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n",
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n",
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n",
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n",
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n",
      "/Users/manage/Desktop/amp_pd/rnaseq/code/cal_additional_scores.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[c + '_impute'] = new\n"
     ]
    }
   ],
   "source": [
    "### calculate additional scores\n",
    "## calculate tremor/pigd\n",
    "tremor_items_columns=['NP2TRMR','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
    "pigd_items_columns=['NP2WALK','NP2FREZ','NP3GAIT','NP3FRZGT','NP3PSTBL']\n",
    "tremor_scores,pigd_scores,ratio,phenotype=cal_tremor(clinical_df,tremor_items_columns,pigd_items_columns)\n",
    "# append to df\n",
    "clinical_df['tremor_scores']=tremor_scores\n",
    "clinical_df['pigd_scores']=pigd_scores\n",
    "\n",
    "## calculate GCO\n",
    "gco_items=['NP1RTOT','NP1PTOT','NP2PTOT','NP3TOT','MSEADLG','MCATOT']\n",
    "gco=cal_gco(clinical_df,gco_items)\n",
    "clinical_df['gco']=gco\n",
    "\n",
    "### select clinical total scores\n",
    "clinical_df['updrs1']=clinical_df['NP1RTOT']+clinical_df['NP1PTOT']\n",
    "clinical_keep_dict={'NP2PTOT':'updrs2','NP3TOT':'updrs3','NP4TOT':'updrs4','MSEADLG':'schwab',\n",
    "                    'tremor_scores':'tremor_scores','pigd_scores':'pigd_scores',#'tremor_pigd_category':'tremor_pigd_category',\n",
    "                    'MCATOT_imputeBL':'moca','JLO_TOTCALC':'benton','DVT_DELAYED_RECALL':'hvlt_delayed_recall','DVT_RECOG_DISC_INDEX':'hvlt_recog_disc_index',\n",
    "                    'DVT_RETENTION':'hvlt_retention','DVT_TOTAL_RECALL':'hvlt_total_recall','DVS_LNS':'lns','DVT_SFTANIM':'semantic_fluency',\n",
    "                    'DVT_SDM':'symbol_digit','geriatric_total':'gds','stai_total':'stai','scopa_total':'scopa','rem_total':'rem',\n",
    "                    'ess_total':'ess','quip_total':'quip','updrs1':'updrs1','gco':'gco'}#'TOTAL_CORRECT':'upsit',\n",
    "clinical_df=clinical_df[['PATNO','EVENT_ID','INFODT']+list(clinical_keep_dict.keys())]\n",
    "clinical_df.rename(columns=clinical_keep_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove visits without date:982\n"
     ]
    }
   ],
   "source": [
    "### select biomarker\n",
    "biospecimen_df=biospecimen_df[['PATNO','EVENT_ID']+['alpha_syn', 'total_tau', 'abeta_42', 'p_tau181p']]\n",
    "\n",
    "### merge longitudinal\n",
    "pd_new = patient_visit_df.merge(clinical_df, on=['PATNO','EVENT_ID','INFODT'], how='outer')\n",
    "pd_new = pd_new.merge(ledd_df, on=['PATNO','EVENT_ID','INFODT'], how='outer')\n",
    "pd_new = pd_new.merge(biospecimen_df, on=['PATNO','EVENT_ID'], how='outer')\n",
    "\n",
    "## remove INFODT is null\n",
    "df2 = pd_new.loc[pd_new['INFODT'].notna()]\n",
    "print('remove visits without date:'+str(len(set(df2.PATNO))))\n",
    "df2.set_index(['PATNO','EVENT_ID','INFODT'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/4007754615.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['moca']=30-df2['moca']\n",
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/4007754615.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['semantic_fluency']=col_max['semantic_fluency']-df2['semantic_fluency']\n"
     ]
    }
   ],
   "source": [
    "###### normalize\n",
    "### 1. convert raw scores to the percentage of the maximum for that scale\n",
    "### 2. normalized by population baseline mean and std\n",
    "\n",
    "## step 1: scale\n",
    "# trait maximum value\n",
    "col_max=df2.max(axis=0)\n",
    "# reverse moca and semantic_fluency\n",
    "df2['moca']=30-df2['moca']\n",
    "df2['semantic_fluency']=col_max['semantic_fluency']-df2['semantic_fluency']\n",
    "df2_impute=df2/col_max\n",
    "## step2: normalize\n",
    "df2_impute_bl=df2_impute.loc[(slice(None), 'BL'), :]\n",
    "bl_mean=df2_impute_bl.mean(axis=0)\n",
    "bl_std=df2_impute_bl.std(axis=0)\n",
    "df2_norm=(df2_impute-bl_mean)/bl_std\n",
    "df2_norm=df2_norm.reset_index()\n",
    "\n",
    "###### Merge static and longitudinal\n",
    "df=df2_norm.merge(df1,on=['PATNO'],how='inner')\n",
    "\n",
    "###### add additional covariated and normalize by z-score\n",
    "## PD_duration, visit-diagnosis_date, month\n",
    "pd_duration_days=pd.to_datetime(df.INFODT,format='%m/%Y')-pd.to_datetime(df.diagnosis_date,format='%m/%Y')\n",
    "pd_duration = stats.zscore(pd_duration_days/np.timedelta64(1, 'M'))\n",
    "pd_duration_norm = list(pd_duration)\n",
    "df['pd_duration_norm']=pd_duration_norm\n",
    "\n",
    "## PD symptom duration, visit-symptom_date, month\n",
    "pd_duration_days=pd.to_datetime(df.INFODT,format='%m/%Y')-pd.to_datetime(df.symptom_date,format='%m/%Y')\n",
    "symtom_duration=list(stats.zscore(pd_duration_days/np.timedelta64(1, 'M')))\n",
    "df['symtom_duration_norm']=symtom_duration\n",
    "\n",
    "## time, visit-baseline, year\n",
    "time=[]\n",
    "for i in range(df.shape[0]):\n",
    "    patno=df.iloc[i,:]['PATNO']\n",
    "    event=df.iloc[i,:]['EVENT_ID']\n",
    "    date=df.iloc[i,:]['INFODT']\n",
    "    bl=df.loc[(df.PATNO==patno) & (df.EVENT_ID=='BL')]['INFODT']\n",
    "    diff=pd.to_datetime(date,format='%m/%Y')-pd.to_datetime(bl,format='%m/%Y')#event date - baseline date\n",
    "    diff=diff/np.timedelta64(1, 'Y')\n",
    "    time.append(diff.values[0])\n",
    "df['time']=time\n",
    "\n",
    "#age at onset, diagnosis date - birthdate, year, and z-score normalize\n",
    "age_days=pd.to_datetime(df.diagnosis_date,format='%m/%Y')-pd.to_datetime(df.BIRTHDT,format='%m/%Y')\n",
    "age=list(stats.zscore(age_days/np.timedelta64(1, 'Y')))\n",
    "df['age_onset_norm']=age\n",
    "\n",
    "# norm LEDD\n",
    "ledd_norm=list(stats.zscore(df.LEDD))\n",
    "df['ledd_norm']=ledd_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PATNO', 'EVENT_ID', 'INFODT', 'updrs2', 'updrs3', 'updrs4', 'schwab',\n",
      "       'tremor_scores', 'pigd_scores', 'moca', 'benton', 'hvlt_delayed_recall',\n",
      "       'hvlt_recog_disc_index', 'hvlt_retention', 'hvlt_total_recall', 'lns',\n",
      "       'semantic_fluency', 'symbol_digit', 'gds', 'stai', 'scopa', 'rem',\n",
      "       'ess', 'quip', 'updrs1', 'gco', 'LEDD', 'alpha_syn', 'total_tau',\n",
      "       'abeta_42', 'p_tau181p', 'symptom_date', 'diagnosis_date',\n",
      "       'is_family_pd', 'COHORT', 'ENROLL_DATE', 'ENROLL_AGE', 'BIRTHDT', 'SEX',\n",
      "       'HANDED', 'EDUCYRS', 'is_white', 'pd_duration_norm',\n",
      "       'symtom_duration_norm', 'time', 'age_onset_norm', 'ledd_norm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append baseline values as a new column\n",
    "value_columns=['updrs2', 'updrs3', 'updrs4', 'schwab',\n",
    "       'tremor_scores', 'pigd_scores', 'moca', 'benton', 'hvlt_delayed_recall',\n",
    "       'hvlt_recog_disc_index', 'hvlt_retention', 'hvlt_total_recall', 'lns',\n",
    "       'semantic_fluency', 'symbol_digit', 'gds', 'stai', 'scopa', 'rem',\n",
    "       'ess', 'quip', 'updrs1', 'gco', 'LEDD', 'alpha_syn', 'total_tau','abeta_42', 'p_tau181p']#trait columns\n",
    "for value_col in value_columns:\n",
    "    bl_df = df[df['EVENT_ID'] == 'BL'][['PATNO', value_col]].rename(columns={value_col: f'{value_col}.BL'})\n",
    "    df = df.merge(bl_df, on='PATNO', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=df.loc[df['time']<3.5]#select data within 3 yr follow-ups (to align with RNAseq data time)\n",
    "filtered_df = df_sub.groupby('PATNO').filter(lambda x: (x['time'].size > 1) & (x['time'].max() > 0.5))#remove if only has 1 visit or visit gap < 0.5 yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695, 7)\n",
      "(1695, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/886054031.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  append_meta_static['PID']=['PP-'+str(i) for i in append_meta_static['PATNO']]#reformat patient id to the meta_df format\n",
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/886054031.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  append_meta_static.drop_duplicates(inplace=True,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "## read meta\n",
    "meta_df=pd.read_csv('../data/meta.csv')\n",
    "meta_df=meta_df.loc[meta_df['Group']=='PD']#select PD only\n",
    "sample_ids=[int(i.split('-')[1]) for i in meta_df.PID]\n",
    "print(meta_df.shape)\n",
    "# select patients have RNAseq\n",
    "filtered_df_sub=filtered_df.loc[filtered_df['PATNO'].isin(sample_ids)]\n",
    "\n",
    "## append static value to meta\n",
    "append_meta_static=filtered_df_sub[['PATNO','is_family_pd','age_onset_norm']]#columns that append to meta\n",
    "append_meta_static['PID']=['PP-'+str(i) for i in append_meta_static['PATNO']]#reformat patient id to the meta_df format\n",
    "append_meta_static.drop_duplicates(inplace=True,ignore_index=True)\n",
    "\n",
    "meta_df=pd.merge(meta_df,append_meta_static,on=['PID'],how='left')\n",
    "print(meta_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visit_month(df):\n",
    "    time=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        patno=df.iloc[i,:]['PATNO']\n",
    "        date=df.iloc[i,:]['INFODT']\n",
    "        bl=df.loc[(df.PATNO==patno) & (df.EVENT_ID=='BL')]['INFODT']\n",
    "        if len(bl)>0:# if has BL. Some only have SC\n",
    "            bl=bl.item()\n",
    "            diff=int(date.split('/')[0])-int(bl.split('/')[0])+(int(date.split('/')[1])-int(bl.split('/')[1]))*12#event date - baseline date in month\n",
    "            time.append(diff)\n",
    "        else:\n",
    "            time.append(None)\n",
    "    df['visit_month']=time\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/2960120966.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['visit_month']=time\n",
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/138879727.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  append_meta_longi.drop_duplicates(inplace=True,ignore_index=True)\n",
      "/var/folders/xg/lz8bx5l17f50vhm9f9lgvg2r0000gn/T/ipykernel_21975/138879727.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  append_meta_longi['ind']=['PP-'+str(append_meta_longi.iloc[i,:].PATNO)+'|'+str(int(append_meta_longi.iloc[i,:].visit_month)) for i in range(append_meta_longi.shape[0])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1695, 11)\n"
     ]
    }
   ],
   "source": [
    "## append longitudinal value to meta\n",
    "append_meta_longi=filtered_df_sub[['PATNO','INFODT','EVENT_ID','pd_duration_norm','ledd_norm']]\n",
    "append_meta_longi=get_visit_month(append_meta_longi)\n",
    "append_meta_longi.drop_duplicates(inplace=True,ignore_index=True)\n",
    "# create ind to merge\n",
    "append_meta_longi['ind']=['PP-'+str(append_meta_longi.iloc[i,:].PATNO)+'|'+str(int(append_meta_longi.iloc[i,:].visit_month)) for i in range(append_meta_longi.shape[0])]\n",
    "meta_df['ind']=[meta_df.iloc[i,:].PID+'|'+str(int(meta_df.iloc[i,:].Timepoint)) for i in range(meta_df.shape[0])]\n",
    "\n",
    "meta_df=pd.merge(meta_df,append_meta_longi[['ind','pd_duration_norm','ledd_norm']],on=['ind'],how='left')\n",
    "meta_df.drop_duplicates(inplace=True,ignore_index=True)#3791's BL and V01 are the same date so there is one duplicate\n",
    "meta_df.drop(columns=['ind','PATNO'],inplace=True)\n",
    "print(meta_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### select a subset of RNA count \n",
    "count=pd.read_csv('../data/data.csv',index_col=0)\n",
    "sub_count=count[[i for i in list(count.columns) if i in list(meta_df['ID'])]]# select samples that have meta data\n",
    "### select transcript of protein-coding genes only\n",
    "protein_coding_genes = pd.read_csv(\"../data/uniprot_annotated_proteome_transcript-to-gene-id.csv\")\n",
    "keep=[i for i in list(count.index) if i.split('.')[0] in list(protein_coding_genes['ensembl_gene_id'])]\n",
    "sub_count=sub_count.loc[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_sub.to_csv('../data/planB_clinical.csv',index=False)\n",
    "meta_df.to_csv('../data/planB_meta.csv',index=False)\n",
    "sub_count.to_csv('../data/planB_count.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
